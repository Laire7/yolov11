{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4274ab6e-1d63-4260-9392-ae14f4301f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.6 �윓� Python-3.10.15 torch-2.4.1 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 C:\\Users\\SBA\\yolo\\bus.jpg: 640x480 4 persons, 1 bus, 31.2ms\n",
      "Speed: 0.0ms preprocess, 31.2ms inference, 62.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mruns\\detect\\predict4\u001b[0m\n",
      "�윊� Learn more at https://docs.ultralytics.com/modes/predict\n",
      "\u001b[34m\u001b[1mVS Code:\u001b[0m view Ultralytics VS Code Extension �슒 at https://docs.ultralytics.com/integrations/vscode\n"
     ]
    }
   ],
   "source": [
    "!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e63c509-dc69-434b-9eef-cec272cf66dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   904  100   904    0     0   1901      0 --:--:-- --:--:-- --:--:--  1915\n",
      "\n",
      "  0 45.9M    0 26079    0     0  27060      0  0:29:41 --:--:--  0:29:41 27060\n",
      "  1 45.9M    1  655k    0     0   336k      0  0:02:20  0:00:01  0:02:19  638k\n",
      " 29 45.9M   29 13.4M    0     0  4524k      0  0:00:10  0:00:03  0:00:07 6615k\n",
      " 78 45.9M   78 35.9M    0     0  9324k      0  0:00:05  0:00:03  0:00:02 12.0M\n",
      "100 45.9M  100 45.9M    0     0  10.3M      0  0:00:04  0:00:04 --:--:-- 13.2M\n",
      "curl: (3) URL rejected: Bad hostname\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0curl: (6) Could not resolve host: unzip\n",
      "curl: (3) URL rejected: Bad hostname\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0curl: (6) Could not resolve host: rm\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: roboflow.zip\n"
     ]
    }
   ],
   "source": [
    "!curl -L \"https://public.roboflow.com/ds/oe8YitNMeB?key=1ew90yaJWA\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "598ecbd5-0983-428e-a63d-a21d580bea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zipfile.ZipFile('roboflow.zip').extractall('./dataset2') # './' 현재 폴더 아래에다, dataset 폴더 만들어서 zip 압축 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "266e0b39-d386-4e3d-ae4e-77f796d5c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e4eac12-4390-4d20-9ca4-88d69054cc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.6 �윓� Python-3.10.15 torch-2.4.1 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=./dataset2/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sba\\miniconda3\\envs\\yolov11\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 559, in get_dataset\n",
      "    data = check_det_dataset(self.args.data)\n",
      "  File \"C:\\Users\\sba\\miniconda3\\envs\\yolov11\\lib\\site-packages\\ultralytics\\data\\utils.py\", line 328, in check_det_dataset\n",
      "    raise FileNotFoundError(m)\n",
      "FileNotFoundError: \n",
      "Dataset 'dataset2/data.yaml' images not found \\u26a0\\ufe0f, missing path 'C:\\Users\\SBA\\datasets\\dataset2\\valid\\images'\n",
      "Note dataset download directory is 'C:\\Users\\SBA\\datasets'. You can update this in 'C:\\Users\\SBA\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sba\\miniconda3\\envs\\yolov11\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\sba\\miniconda3\\envs\\yolov11\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\sba\\miniconda3\\envs\\yolov11\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "    sys.exit(entrypoint())\n",
      "  File \"C:\\Users\\sba\\miniconda3\\envs\\yolov11\\lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 831, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "  File \"C:\\Users\\sba\\miniconda3\\envs\\yolov11\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 796, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "  File \"C:\\Users\\sba\\miniconda3\\envs\\yolov11\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 133, in __init__\n",
      "    self.trainset, self.testset = self.get_dataset()\n",
      "  File \"C:\\Users\\sba\\miniconda3\\envs\\yolov11\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 563, in get_dataset\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error \\u274c {e}\")) from e\n",
      "RuntimeError: Dataset 'dataset2/data.yaml' error  \n",
      "Dataset 'dataset2/data.yaml' images not found , missing path 'C:\\Users\\SBA\\datasets\\dataset2\\valid\\images'\n",
      "Note dataset download directory is 'C:\\Users\\SBA\\datasets'. You can update this in 'C:\\Users\\SBA\\AppData\\Roaming\\Ultralytics\\settings.json'\n"
     ]
    }
   ],
   "source": [
    "!yolo detect train data=./dataset2/data.yaml model=yolo11n.pt epochs=100 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c422faaa-08d7-4aae-b31a-1de2551b3cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SBA\\\\yolo'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5dbffe9-bd3d-411b-b84c-9529bad75f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# # Load a model\n",
    "# model = YOLO(\"yolo11n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# # Train the model with MPS\n",
    "# results = model.train(data=\"./dataset/data.yaml\", epochs=100, imgsz=640, device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dac2a950-9250-4852-8923-e52b2b009b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# 모델을 GPU 또는 CPU에 할당\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0fe8acd-d7a5-4f57-9782-94e6b399a73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=./dataset2/data.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train14\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\SBA\\yolo\\dataset2\\train\\labels... 465 images, 0 backgrounds, 0 corrupt: 100%|██████████| 46\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\SBA\\yolo\\dataset2\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\SBA\\yolo\\dataset2\\valid\\labels... 133 images, 0 backgrounds, 0 corrupt: 100%|██████████| 133/\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\SBA\\yolo\\dataset2\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train14\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train14\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      2.49G      1.651      2.874      1.527          7        640: 100%|██████████| 30/30 [00:31<00:00, \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        133        330      0.772     0.0823      0.243      0.125\n",
      "\n",
      "1 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs\\detect\\train14\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\train14\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\train14\\weights\\best.pt...\n",
      "Ultralytics 8.3.6  Python-3.10.15 torch-2.4.1 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        133        330      0.772     0.0823      0.243      0.125\n",
      "Speed: 0.4ms preprocess, 19.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train14\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\").to(device)  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model with MPS\n",
    "results = model.train(data=\"./dataset2/data.yaml\", epochs=1, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef023aba-464b-4ec1-b3fe-948e6265c7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
