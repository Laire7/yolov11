{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc56aa80-b92e-45fe-9fb5-03e989600d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af2f09db-95dc-490f-bae3-9670c0a683f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import cv2, os, shutil\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16073241-b065-44cf-8152-39358b8e59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_COLOR = (255, 0, 0) # Red\n",
    "TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "def visualize_bbox(img, bbox, class_name, pic_w, pic_h, color=BOX_COLOR, thickness=2):\n",
    "    dataType = \"yolo\"\n",
    "\n",
    "    \"\"\"Visualizes a single bounding box on the image\"\"\"\n",
    "\n",
    "    if dataType == 'coco':\n",
    "        x_min, y_min, w, h = bbox # 정규화 된 0~1 사이의 값\n",
    "        x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "    elif dataType == \"yolo\":\n",
    "        x_center, y_center, w, h = bbox\n",
    "        # 픽셀 좌표로 변환 이미지의 width와 height값\n",
    "        x_min = int(float(x_center - w/2) * pic_w)\n",
    "        x_max = int(float(x_center + w/2) * pic_w)\n",
    "        y_min = int(float(y_center - h/2) * pic_h)\n",
    "        y_max = int(float(y_center + h/2) * pic_h)\n",
    "    print(w, h)\n",
    "    print(x_min, y_min, y_min, y_max)\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "\n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)\n",
    "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35,\n",
    "        color=TEXT_COLOR,\n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return img\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids, category_id_to_name, img_shape):\n",
    "    img = image.copy()\n",
    "    h,w = img_shape[0:2]\n",
    "    print(bboxes)\n",
    "    print(category_ids)\n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "        class_name = category_id_to_name[category_id]\n",
    "        img = visualize_bbox(img, bbox, class_name, w, h)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a90048c-1e7b-4361-b536-730f4d049fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SBA\\yolo\\yolov11\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob \n",
    "\n",
    "currDir = os.getcwd()\n",
    "print(currDir)\n",
    "\n",
    "# 데이터 증식 폴더 만들기\n",
    "augFolder = 'kAug_multOverBatch'\n",
    "augDataDir = os.path.join(currDir, augFolder)\n",
    "\n",
    "if os.path.exists(augDataDir):\n",
    "    shutil.rmtree(augDataDir)\n",
    "os.mkdir(augDataDir)\n",
    "\n",
    "# 원본 데이터셋이 저장된 폴더\n",
    "orgDataPath = 'C:\\\\Users\\\\SBA\\\\yolo\\\\yolov11\\\\kOrig_multOver'\n",
    "imagefiles = glob(os.path.join(orgDataPath, '*.JPG'))\n",
    "labelfiles = glob(os.path.join(orgDataPath, '*.txt'))\n",
    "# print(imagefiles)\n",
    "# print(labelfiles)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d220c61-ab4c-425e-b823-7e513b7469c0",
   "metadata": {},
   "source": [
    "# 이미지 파일과 txt파일이 동일하게 한쌍으로 존재하는지 확인\n",
    "correct = 0\n",
    "for i in range(len(imagefiles)):\n",
    "    if str(imagefiles[i].split('.jpg'))==str(labelfiles[i].split('.txt')):\n",
    "        correct +=1\n",
    "print(\"correct: {}/{}\".format(correct,len(imagefiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8527712b-ab38-473c-933c-196f88a67725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label_txt(txtFile):\n",
    "    category_ids = []\n",
    "    bboxes = []\n",
    "\n",
    "    f=open(txtFile,'r')\n",
    "\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: break\n",
    "        ids, xc, yc, w, h= line.split(' ')\n",
    "        category_ids.append(int(ids))\n",
    "        bboxes.append([float(xc),float(yc),float(w),float(h)])\n",
    "        #print(line)\n",
    "    f.close()\n",
    "    return category_ids, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc893fc3-b4b2-449d-9d72-ccdcdd912d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_label_txt(txtFile, category_ids, bboxes):\n",
    "    f=open(txtFile,'w')\n",
    "\n",
    "    for i, ids in enumerate(category_ids):\n",
    "        xc,yc,w,h = bboxes[i]\n",
    "        f.write(\"{} {} {} {} {}\\n\".format(int(ids),xc,yc,w,h))\n",
    "        #print(\"{} {}\".format(int(ids), bboxes[i]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f429144-d869-416e-be61-f5629a8eee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id_to_name = {0: 'kido'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d01b0e4-ad6d-4ea9-9af2-dfb76ba45c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_resize = A.Compose(\n",
    "    [A.LongestMaxSize(max_size=800, interpolation=cv2.INTER_LINEAR),],\n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['category_ids']),\n",
    ")\n",
    "\n",
    "transform_hflip = A.Compose(\n",
    "    [A.HorizontalFlip(p=1.0)],\n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['category_ids']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd9c62f-3d57-4a04-ac8b-a19b10eb441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "def dataAug(func, imagefiles, augDir):\n",
    "    for imagefile in imagefiles:\n",
    "        image = cv2.imread(imagefile)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        img_height, img_width = image.shape[0:2]\n",
    "    \n",
    "        # txt파일은 이미지 파일에서 확장자만 다르다!\n",
    "        readTxtFile = imagefile.split('.')[0] + '.txt'\n",
    "        baseName = os.path.basename(imagefile).split('.')[0]\n",
    "        writeTxtFile = os.path.join(augDir, str(baseName+'.txt'))\n",
    "        category_ids, bboxes = read_label_txt(readTxtFile)\n",
    "        \n",
    "        if func=='hflip':\n",
    "            transformed = transform_hflip(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "            saveImageName = baseName + '_hflip.JPG'  \n",
    "            saveLabelName = baseName + '_hflip.txt'\n",
    "            saveImage = cv2.cvtColor(transformed['image'], cv2.COLOR_RGB2BGR)\n",
    "            saveImgPath = os.path.join(augDir, saveImageName)\n",
    "            saveLabelPath = os.path.join(augDir, saveLabelName)\n",
    "            cv2.imwrite(saveImgPath, saveImage)\n",
    "            write_label_txt(saveLabelPath, transformed['category_ids'], transformed['bboxes'])            \n",
    "        elif func=='rotate':\n",
    "            angle_inter = 20\n",
    "            for angle in range(angle_inter,360,angle_inter):\n",
    "                transform_rotate = A.Compose(\n",
    "                    [A.Rotate(limit=(angle,angle), rotate_method='largest_box', p=1.0)],\n",
    "                    bbox_params=A.BboxParams(format='yolo', label_fields=['category_ids'])\n",
    "                )\n",
    "                transformed = transform_rotate(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "                saveImageName = baseName + '_rotate_{}.JPG'.format(angle)  \n",
    "                saveLabelName = baseName + '_rotate_{}.txt'.format(angle)  \n",
    "                saveImage = cv2.cvtColor(transformed['image'], cv2.COLOR_RGB2BGR)\n",
    "                saveImgPath = os.path.join(augDir, saveImageName)\n",
    "                saveLabelPath = os.path.join(augDir, saveLabelName)\n",
    "                cv2.imwrite(saveImgPath, saveImage)\n",
    "                write_label_txt(saveLabelPath, transformed['category_ids'], transformed['bboxes'])\n",
    "        elif func=='resize':\n",
    "            transformed = transform_resize(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "            saveImageName = baseName + '.JPG'  \n",
    "            saveLabelName = baseName + '.txt'            \n",
    "            saveImage = cv2.cvtColor(transformed['image'], cv2.COLOR_RGB2BGR)\n",
    "            saveImgPath = os.path.join(augDir, saveImageName)\n",
    "            saveLabelPath = os.path.join(augDir, saveLabelName)\n",
    "            cv2.imwrite(saveImgPath, saveImage)\n",
    "            write_label_txt(saveLabelPath, transformed['category_ids'], transformed['bboxes'])\n",
    "            \n",
    "        if DEBUG==True:\n",
    "            visualize(\n",
    "                transformed['image'],\n",
    "                transformed['bboxes'],\n",
    "                transformed['category_ids'],\n",
    "                category_id_to_name,\n",
    "                img_width, img_height\n",
    "            )\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03ce59e3-95f9-4938-a194-87d7d87510f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAug('resize', imagefiles, augDataDir)\n",
    "dataAug('hflip', imagefiles, augDataDir)\n",
    "dataAug('rotate', imagefiles, augDataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa7958a4-9e99-4678-8e3e-dd34c0ab0a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolo11n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c63973af-9555-41f5-8b63-3b6b389d56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small데이터셋을 위한 폴더를 지정하고 4000장을 나눠서 보관\n",
    "import os, shutil\n",
    "\n",
    "sdata = os.path.join(os.getcwd(), 'kAug_multOverBatch_tvt')\n",
    "\n",
    "if os.path.exists(sdata):\n",
    "    shutil.rmtree(sdata)\n",
    "os.makedirs(sdata)\n",
    "\n",
    "train_sdata = os.path.join(sdata,'train')\n",
    "valid_sdata = os.path.join(sdata,'valid')\n",
    "test_sdata = os.path.join(sdata,'test')\n",
    "\n",
    "trainValidTestList = ['train','valid','test']\n",
    "\n",
    "os.makedirs(train_sdata, exist_ok=True)\n",
    "os.makedirs(valid_sdata, exist_ok=True)\n",
    "os.makedirs(test_sdata, exist_ok=True)\n",
    "\n",
    "train_sdata_kido = os.path.join(train_sdata,'kido')\n",
    "os.makedirs(train_sdata_kido, exist_ok=True)\n",
    "\n",
    "valid_sdata_kido = os.path.join(valid_sdata,'kido')\n",
    "os.makedirs(valid_sdata_kido, exist_ok=True)\n",
    "\n",
    "test_sdata_kido = os.path.join(test_sdata,'kido')\n",
    "os.makedirs(test_sdata_kido, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "530549d3-8b69-4b0e-bb9b-37b6c2d50283",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRatio = 0.6\n",
    "validRatio = 0.2\n",
    "testRatio = 1 - trainRatio - validRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb09e924-ebcd-487e-a772-0dc22339a858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [0, 21] valid [22, 28] test [29, 37]\n"
     ]
    }
   ],
   "source": [
    "numPath = os.path.join(os.getcwd(), 'kAug')\n",
    "files = os.listdir(numPath)\n",
    "\n",
    "train_num = int(trainRatio * len(files))\n",
    "valid_num = int(validRatio * len(files))\n",
    "test_num  = len(files) - train_num - valid_num\n",
    "\n",
    "train_range = [0, train_num-1]\n",
    "valid_range = [train_num, train_num + valid_num -1]\n",
    "test_range  = [train_num + valid_num, train_num + valid_num + test_num-1]\n",
    "print(f'train {train_range} valid {valid_range} test {test_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0f59f96-21bd-4ad5-9df4-7d14e24e62f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 분할 및 복사가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# 데이터셋 디렉토리 경로 설정 (데이터셋이 저장된 경로로 수정하세요)\n",
    "dataset_dir = os.path.join(os.getcwd(), 'kAug_multOverBatch')\n",
    "\n",
    "# 새로운 train, valid, test 디렉토리 생성 경로\n",
    "base_dir = os.path.join(os.getcwd(), 'kAug_multOverBatch_tvt')\n",
    "\n",
    "# 클래스 목록\n",
    "classes = ['kido']\n",
    "\n",
    "# 폴더 경로 생성\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# 폴더 생성 함수\n",
    "def create_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "# train, valid, test 폴더 및 각각의 클래스 폴더 생성\n",
    "for cls in classes:\n",
    "    create_dir(os.path.join(train_dir, cls))\n",
    "    create_dir(os.path.join(valid_dir, cls))\n",
    "    create_dir(os.path.join(test_dir, cls))\n",
    "\n",
    "# 이미지 복사 함수\n",
    "def copy_images(start_idx, end_idx, src_dir, dst_dir, label):\n",
    "    srcFiles = os.listdir(src_dir)\n",
    "    # print(f'be_sh {srcFiles}')\n",
    "    srcFiles = random.sample(srcFiles, len(srcFiles))\n",
    "    # print(f'af_sh {srcFiles}')\n",
    "    for i in range(start_idx, end_idx + 1):\n",
    "        file_name = f'{label}.{i}.jpg'\n",
    "        # print(f' fileName {file_name}')\n",
    "        src_path = os.path.join(src_dir, srcFiles[i])\n",
    "        # print(f'src {src_path}')\n",
    "        dst_path = os.path.join(dst_dir, file_name)\n",
    "        # print(f'dst {dst_path}')\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "# 클래스별로 train, valid, test 데이터셋 구성\n",
    "for cls in classes:\n",
    "    copy_images(train_range[0], train_range[1], os.path.join(dataset_dir), os.path.join(train_dir, cls), cls)\n",
    "    # print(train_range[0], train_range[1], dataset_dir, os.path.join(train_dir, cls))\n",
    "\n",
    "    # valid dataset 구성 (1000~1249)\n",
    "    copy_images(valid_range[0], valid_range[1], os.path.join(dataset_dir), os.path.join(valid_dir, cls), cls)\n",
    "\n",
    "    # test dataset 구성 (1250~1499)\n",
    "    copy_images(test_range[0], test_range[1], os.path.join(dataset_dir), os.path.join(test_dir, cls), cls)\n",
    "\n",
    "print(\"데이터셋 분할 및 복사가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a883d10b-0b50-4ef1-a76d-ab7881b2d7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train28, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train28\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\SBA\\yolo\\yolov11\\kDataset_yolo\\train\\labels.cache... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\SBA\\yolo\\yolov11\\kDataset_yolo\\valid\\labels.cache... 7 images, 0 backgrounds, 0 corrupt: 100%|██████████| 7/7 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train28\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train28\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.183      2.672      1.332         34        640: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          7         14    0.00667          1      0.569      0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      1.162      2.695       1.31         35        640: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          7         14    0.00619      0.929      0.722      0.382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G      1.021      2.654      1.232         37        640: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          7         14    0.00619      0.929      0.688      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/50         0G     0.8307      2.436      1.157         38        640: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          7         14    0.00667          1      0.741      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G     0.7179      2.369      1.088         32        640: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          7         14    0.00619      0.929      0.805      0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G     0.7577      2.172      1.029         32        640: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          7         14    0.00667          1      0.777      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G     0.7233       2.03      1.026         50        640: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          7         14    0.00667          1      0.787      0.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G     0.7157      1.813     0.9902         33        640: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          7         14    0.00667          1      0.796      0.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G     0.6705      1.811      1.051         47        640:  50%|█████     | 1/2 [00:02<00:02,  2.74s/it]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 4699140 bytes in function 'cv::OutOfMemoryError'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\ultralytics\\engine\\model.py:802\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 802\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\ultralytics\\engine\\trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\ultralytics\\engine\\trainer.py:367\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    365\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m TQDM(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader), total\u001b[38;5;241m=\u001b[39mnb)\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_batch_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;66;03m# Warmup\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\ultralytics\\data\\build.py:48\u001b[0m, in \u001b[0;36mInfiniteDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a sampler that repeats indefinitely.\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\ultralytics\\data\\base.py:288\u001b[0m, in \u001b[0;36mBaseDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m    287\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns transformed label information for given index.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_and_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\ultralytics\\data\\base.py:294\u001b[0m, in \u001b[0;36mBaseDataset.get_image_and_label\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    292\u001b[0m label \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[index])  \u001b[38;5;66;03m# requires deepcopy() https://github.com/ultralytics/ultralytics/pull/1948\u001b[39;00m\n\u001b[0;32m    293\u001b[0m label\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# shape is for rect, remove it\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m], label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mori_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m], label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresized_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mratio_pad\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    296\u001b[0m     label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresized_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mori_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    297\u001b[0m     label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresized_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mori_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    298\u001b[0m )  \u001b[38;5;66;03m# for evaluation\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrect:\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\ultralytics\\data\\base.py:163\u001b[0m, in \u001b[0;36mBaseDataset.load_image\u001b[1;34m(self, i, rect_mode)\u001b[0m\n\u001b[0;32m    161\u001b[0m         im \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(f)  \u001b[38;5;66;03m# BGR\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# read image\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# BGR\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage Not Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Users\\sba\\miniconda3\\envs\\album\\lib\\site-packages\\ultralytics\\utils\\patches.py:26\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR):\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    Read an image from a file.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m        (np.ndarray): The read image.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 4699140 bytes in function 'cv::OutOfMemoryError'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "results = model.train(data='data.yaml', epochs=50, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a7b88-2573-4bb9-b5cc-d9c57e188394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02078cd8-ddec-4218-b278-76826fbb2abf",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
